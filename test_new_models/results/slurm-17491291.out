nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Thu_Feb_10_18:23:41_PST_2022
Cuda compilation tools, release 11.6, V11.6.112
Build cuda_11.6.r11.6/compiler.30978841_0
Wed Jan 31 10:57:09 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA TITAN Xp     On   | 00000000:AF:00.0 Off |                  N/A |
| 23%   25C    P8     9W / 250W |      0MiB / 12196MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
res-hpc-gpu01.researchlumc.nl
Cuda devices: 0
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at BioLinkBERT-large and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Read files
Converted labels
Tokenized data
Splitted data
Data converted into tensors
  0%|          | 0/192 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/exports/sascstudent/svanderwal2/programs/test_new_models/classify_model_try.py", line 216, in <module>
    main()
  File "/exports/sascstudent/svanderwal2/programs/test_new_models/classify_model_try.py", line 205, in main
    trainer = train_func(model, batch_size, train_data, validation_data, encoded_labels)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/programs/test_new_models/classify_model_try.py", line 127, in train_func
    trainer.train()
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/trainer.py", line 1555, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/trainer.py", line 1860, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/trainer.py", line 2725, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/trainer.py", line 2748, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1564, in forward
    outputs = self.bert(
              ^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1013, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 607, in forward
    layer_outputs = layer_module(
                    ^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 497, in forward
    self_attention_outputs = self.attention(
                             ^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 427, in forward
    self_outputs = self.self(
                   ^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/exports/sascstudent/svanderwal2/miniconda3/envs/run_models_sasc/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 349, in forward
    attention_scores = attention_scores / math.sqrt(self.attention_head_size)
                       ~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 11.91 GiB of which 122.94 MiB is free. Including non-PyTorch memory, this process has 11.79 GiB memory in use. Of the allocated memory 11.20 GiB is allocated by PyTorch, and 12.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  0%|          | 0/192 [00:30<?, ?it/s]
